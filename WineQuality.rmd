---
title: "DDS 6306 Wine Quality - Final Project"
output: html_document
date: "2024-11-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Wine Quality

## Environment Preparation

```{r}
library(tidyverse)
library(caret)
library(class)
library(e1071)
library(corrplot)
library(FNN)
library(car)
library(GGally)
library(naivebayes)
library(ggcorrplot)
library(dplyr)
library(furrr)
library(parallel)
library(progressr)
library(DT)
```

## Data Inspection

```{r}

wine_train = read.csv('./Wine_Train.csv', header = TRUE)
wine_test = read.csv("./Wine_Test_Set.csv", header = TRUE)
wine_type_location = read.csv('./Wine_Types_and_Locations.csv', header = TRUE)

type_mode <- tolower(names(sort(table(wine_type_location$type), decreasing = TRUE))[1])
location_mode <- tolower(names(sort(table(wine_type_location$location), decreasing = TRUE))[1])

wine_type_location <- wine_type_location |> mutate(
  type = ifelse(is.na(type) | type == "", type_mode, tolower(type)),
  location = ifelse(
    is.na(location) |
      location == "",
    location_mode,
    tools::toTitleCase(location)
  )
) |>
  mutate(location = ifelse(location == "Califormia", "California", location)) |>
  mutate(type = factor(type), location = factor(location))

wine_train <- left_join(wine_train, wine_type_location, by = "ID")

sprintf("Data composed of: %d rows and %d columns",
        nrow(wine_train),
        ncol(wine_train))

head(wine_train, n = 5)
str(wine_train)

emptyData <- colSums(is.na(wine_train))
totalRows <- nrow(wine_train)

tibble(
  Column = names(wine_train),
  `Total_Rows` = totalRows,
  `NA_Count` = emptyData
)
```

### Histogram of the quality

```{r}
ggplot(wine_train, aes(x = quality)) +
  geom_histogram(binwidth = 1, fill = "maroon", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Wine Quality", x = "Quality", y = "Frequency") +
  theme_minimal()
```

### Correlation

```{r}
correlation_matrix = cor(wine_train %>% select_if(is.numeric))
corrplot(correlation_matrix, 
         method = "color",           
         type = "upper",            
         tl.col = "black",          
         tl.srt = 45,               
         addCoef.col = "black",     
         number.cex = 0.7,          
         col = colorRampPalette(c("red", "white", "blue"))(200),  
         diag = FALSE,              
         tl.cex = 0.8)

```

### Variable Inflation

```{r}
vif_data = lm(quality ~ ., data = wine_train %>% select(-ID))
vif_values = vif(vif_data)
print(vif_values)
```

#### Addressing High Inflation

```{r}
high_vif_threshold = 10
features_to_remove = names(vif_values[vif_values > high_vif_threshold])
model_cols = setdiff(names(wine_train %>% select_if(is.numeric)), c("quality", features_to_remove))
sprintf("Removed features with high VIF: %s", features_to_remove)
```

## Feature Construction

### Naive Bayes and Linear Regression

#### Prepare environment and helper functions
```{r}
n_cores <- detectCores()
max_memory <- 16 * 1024 ^ 3
plan(multisession, workers = max(1, n_cores - 2))
options(future.globals.maxSize = max_memory)

evaluateModels <- function(target, features, data_train) {
  train_index <- createDataPartition(data_train[[target]], p = 0.7, list = FALSE)
  train_data <- data_train[train_index, ]
  test_data <- data_train[-train_index, ]
  
  train_x <- train_data[, features, drop = FALSE]
  test_x <- test_data[, features, drop = FALSE]
  train_labels <- factor(train_data[[target]])
  test_labels <- factor(test_data[[target]], levels = levels(train_labels))
  
  ## NB
  formulaNb <- paste(target, "~", paste(features, collapse = " + "))
  nbModel <- naiveBayes(as.formula(formulaNb), data = train_data)
  
  nbPredictions <- predict(nbModel, test_data)
  nbMatrix <- confusionMatrix(factor(nbPredictions, levels = levels(test_labels)), test_labels, mode = "everything")
  
  return(
    list(
      nb_formula = formulaNb,
      nb_accuracy = nbMatrix$overall["Accuracy"],
      nb_sensitivity = mean(nbMatrix$byClass[, "Sensitivity"], na.rm = TRUE),
      nb_specificity = mean(nbMatrix$byClass[, "Specificity"], na.rm = TRUE)
    )
  )
}

evaluateRegression <- function(target, features, data) {
  model <- paste(target, " ~ ", paste(features, collapse = " + "))
  train_indices <- createDataPartition(data[[target]], p = 0.75, list = FALSE)
  train_data <- data[train_indices, ]
  validation_data <- data[-train_indices, ]
  
  fit <- lm(as.formula(model), data = train_data)
  predictions <- predict(fit, newdata = validation_data)
  actual_values <- validation_data[[target]]
  
  residuals <- actual_values - predictions
  mae_value <- mean(abs(residuals))
  
  return(
    list(
      features = model,
      AIC = AIC(fit),
      BIC = BIC(fit),
      MAE = mae_value,
      RMSE = sqrt(mean(residuals ^ 2)),
      ADJUSTED_R2 = summary(fit)$adj.r.squared,
      R2_VALIDATION = 1 - sum(residuals ^ 2) / sum((actual_values - mean(actual_values)) ^ 2)
    )
  )
}

permuteModels <- function(target, data) {
  all_features <- colnames(data)[!colnames(data) %in% target]
  total_features <- length(all_features)
  
  all_combinations <- unlist(lapply(1:total_features, function(size) {
    combn(all_features, size, simplify = FALSE)
  }), recursive = FALSE)
  
  chunk_size <- ceiling(length(all_combinations) / future::nbrOfWorkers())
  chunks <- split(all_combinations, ceiling(seq_along(all_combinations) / chunk_size))
  
  total_steps <- length(all_combinations)
  p <- progressr::progressor(steps = total_steps)
  
  print(paste("Will Run --- ", total_steps, " --- Combinations", collapse = "\n"))
  results <- future_map_dfr(seq_along(chunks), ~ {
    chunk <- chunks[[.x]]
    results_list <- list()
    
    for (i in seq_along(chunk)) {
      features_subset <- chunk[[i]]
      # message(paste("Starting: ", target, " ~ ", paste(features_subset, collapse = " + "), collapse = "\n"))
      knn_nb_results <- data.frame(evaluateModels(target, features_subset, data))
      regression_results <- data.frame(evaluateRegression(target, features_subset, data))
      
      #regression_results <- regression_results[regression_results$adjusted_r2 > 0.7, , drop = FALSE]
      combined_results <- data.frame(
        iteration = paste(.x, "-", i),
        features = paste(features_subset, collapse = ", "),
        nb_accuracy = knn_nb_results$nb_accuracy,
        nb_sensitivity = knn_nb_results$nb_sensitivity,
        nb_specificity = knn_nb_results$nb_specificity,
        AIC = regression_results$AIC,
        BIC = regression_results$BIC,
        MAE = regression_results$MAE,
        RMSE = regression_results$RMSE,
        ADJUSTED_R2 = regression_results$ADJUSTED_R2,
        R2_VALIDATION = regression_results$R2_VALIDATION
      )
      
      results_list[[i]] <- combined_results
      p(paste("Chunk", .x, "complete"))
    }
    
    
    do.call(rbind, results_list)
  }, .options = furrr_options(seed = TRUE))
  
  return(results)
}

runTests <- function(target, data) {
  progressr::with_progress({
    all_results <- permuteModels(target, data)
  })
  
  return(all_results |>
           arrange(MAE) |>
           mutate(across(where(is.numeric), ~ round(.x, 6))))
}

```

#### Excute combinations and display the results

```{r}
results <- runTests("quality", wine_train |> dplyr::select(-ID, -type, -location))
datatable(
  results,
  caption = "Performance Comparison for NB, KNN, and Regression Models",
  options = list(pageLength = 5, autoWidth = TRUE),
  rownames = FALSE
)
```

### Compare with polynomial models


#### Helper functions
```{r}
test_polynomials <- function(data, base_formula, features) {
  results <- data.frame()
  
  for (feature in features) {
    formula_quad <- paste(base_formula, " + I(", feature, "^2)", sep = "")
    formula_cubic <- paste(base_formula, "+ I(", feature, "^2) + I(", feature, "^3)", sep = "")
    
    fit_quad <- lm(as.formula(formula_quad), data = data)
    fit_cubic <- lm(as.formula(formula_cubic), data = data)
    
    mse_quad <- mean(residuals(fit_quad)^2)
    adj_r2_quad <- summary(fit_quad)$adj.r.squared
    
    mse_cubic <- mean(residuals(fit_cubic)^2)
    adj_r2_cubic <- summary(fit_cubic)$adj.r.squared
    
    analysis <- data.frame(
      Feature = feature,
      AIC_QUAD = AIC(fit_quad),
      AIC_CUBIC = AIC(fit_cubic),
      MSE_QUAD = mse_quad,
      MSE_CUBIC = mse_cubic,
      ADJ_R2_QUAD = adj_r2_quad,
      ADJ_R2_CUBIC = adj_r2_cubic,
      FORMULA_CUBIC = formula_cubic,
      FORMULA_QUAD = formula_quad
    )
    results <- rbind(results, analysis)
  }
  
  return(results)
}
```

### Execute adding polynomials and compare

```{r}
model_base <- "quality ~ volatile.acidity + citric.acid + residual.sugar + chlorides + pH + alcohol + sulphates"
# fixed.acidity + citric.acid + chlorides + residual.sugar + pH + alcohol + sulphates + type + location + type * citric.acid  + type * location
features <- c(
  "volatile.acidity",
  "citric.acid",
  "residual.sugar",
  "chlorides",
  "pH",
  "alcohol",
  "sulphates"
)


#volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, sulphates, alcohol

results <- test_polynomials(wine_train, model_base, features)
results <- results[order(results$MSE_QUAD), ]
results
```

### Fitting with Linear Regression

```{r}
set.seed(1233)
train_index <- createDataPartition(wine_train[["quality"]], p = 0.7, list = FALSE)
train_set <- wine_train[train_index, ]
test_set <- wine_train[-train_index, ]

model <- quality ~ fixed.acidity + citric.acid + chlorides + residual.sugar + pH + alcohol + sulphates + type + location
fit <- lm(model, data = train_set)

summary_fit <- summary(fit)
actual_lm <- as.numeric(as.character(test_set$quality))
predicted_quality <- predict(fit, newdata = test_set)
lm_mae <- mean(abs(actual_lm - predicted_quality))

sprintf("MAE: %.6f -- ADJ RSQR: %.6f -- AIC: %.6f",lm_mae, summary_fit$adj.r.squared, AIC(fit))
```

### Fitting with Naive Bayes

```{r}
# nb_model = train(
#   quality_cat ~ .,
#   data = train_set[, c(model_cols, "quality_cat")],
#   method = "naive_bayes",
#   trControl = cv_control
# )
cv_control = trainControl(method = "cv", number = 5)
train_index <- createDataPartition(wine_train[["quality"]], p = 0.7, list = FALSE)
train_set <- wine_train[train_index, ]
test_set <- wine_train[-train_index, ]

train_set$quality <- factor(train_set$quality)
test_set$quality <- factor(test_set$quality, levels = levels(train_set$quality))
nb_fit <- train(
  quality ~ fixed.acidity + citric.acid + chlorides + residual.sugar + pH + alcohol + sulphates + type + location,
  data = train_set,
  method = "naive_bayes",
  trControl = cv_control
  )

```

#### Predictions and MAE for Naive Bayes

```{r}
test_set$quality <- factor(test_set$quality, levels = levels(train_set$quality))
predictions_prob <- predict(nb_fit, newdata = test_set, type = "prob")

quality_levels <- as.numeric(levels(test_set$quality))
predicted_numeric <- apply(predictions_prob, 1, function(x) sum(x * quality_levels))
actual_numeric <- as.numeric(as.character(test_set$quality))
nb_mae <- mean(abs(actual_numeric - predicted_numeric))
sprintf("Mean Absolute Error (MAE): %.6f", nb_mae)
```


## Model MAE comparison

```{r}
model_comparison = data.frame(
  Model = c("Linear Regression", "Naive Bayes"),
  MAE = c(lm_mae, nb_mae)
)
print(model_comparison)

mae_data = data.frame(
  Model = c("Linear Regression", "Naive Bayes"),
  MAE = c(lm_mae, nb_mae)
)

ggplot(model_comparison, aes(x = Model, y = MAE, fill = Model)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(MAE, 4)), vjust = -0.5, size = 4, color = "black") +
  labs(
    title = "Model Comparison by MAE",
    x = "Model",
    y = "Mean Absolute Error"
  ) +
  theme_minimal()
```

### Define model_cols without 'ID' and 'quality'

```{r}
model_cols = setdiff(names(wine_train %>% select_if(is.numeric)), c("ID", "quality"))
feature_correlations_knn = cor(wine_train[, model_cols], wine_train$quality, use = "complete.obs")

feature_importance_knn = data.frame(
  Feature = model_cols,
  Correlation = feature_correlations_knn
) %>% 
  arrange(desc(abs(Correlation)))

ggplot(feature_importance_knn, aes(x = reorder(Feature, Correlation), y = Correlation, fill = Correlation > 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_fill_manual(values = c("red", "blue"), labels = c("Negative", "Positive")) +
  labs(
    title = "Feature Importance for k-NN (Correlation with Quality)",
    x = "Feature",
    y = "Correlation",
    fill = "Direction"
  ) +
  theme_minimal()
```

## Create submission file with ID and predicted Quality

```{r}
create_submission_file = function(test_data, predictions, file_path) {
  submission = data.frame(
    ID = test_data$ID,
    Quality = predictions
  )
  write.csv(submission, file_path, row.names = FALSE)
  sprintf("Submission file created successfully at: %s", file_path)
}
```

### Build Predictions on Test Set

```{r}
# final_knn_predictions = knn.reg(
#   train = as.matrix(wine_train_scaled[, model_cols]),
#   test = as.matrix(wine_test_scaled[, model_cols]),
#   y = wine_train_scaled$quality,
#   k = best_k
# )$pred
```

### Define the file path and call the function

```{r}
# file_path = "Wine_Test_Predictions.csv"
# create_submission_file(wine_test, final_knn_predictions, file_path)
```
